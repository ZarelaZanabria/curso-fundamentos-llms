{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOW0tOPvJrZEX5Wd9syMq7r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"RSXiOUrucBSi","executionInfo":{"status":"ok","timestamp":1738440325879,"user_tz":300,"elapsed":186058,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}},"outputId":"f14bcb73-f18d-41ad-d091-b5d168901f47"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.0)\n","Collecting xformers\n","  Downloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n","Collecting np\n","  Downloading np-1.0.2.tar.gz (7.4 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers) (1.26.4)\n","Collecting torch==2.6.0 (from xformers)\n","  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->xformers)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->xformers)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->xformers)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->xformers)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->xformers)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->xformers)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->xformers)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->xformers)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->xformers)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->xformers)\n","  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->xformers)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting triton==3.2.0 (from torch==2.6.0->xformers)\n","  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->xformers) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->xformers) (3.0.2)\n","Downloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl (44.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: np\n","  Building wheel for np (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for np: filename=np-1.0.2-py3-none-any.whl size=13658 sha256=b49383787c4db346b235dac87b715568ae258aa1030887b6148a0d385590555c\n","  Stored in directory: /root/.cache/pip/wheels/19/20/42/6ee214e617f78123903f603524d662ac6fa14154c3027fd992\n","Successfully built np\n","Installing collected packages: triton, nvidia-cusparselt-cu12, np, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.1.0\n","    Uninstalling triton-3.1.0:\n","      Successfully uninstalled triton-3.1.0\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cu124\n","    Uninstalling torch-2.5.1+cu124:\n","      Successfully uninstalled torch-2.5.1+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n","torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n","fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed np-1.0.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 torch-2.6.0 triton-3.2.0 xformers-0.0.29.post2\n"]}],"source":["!pip install einops xformers np"]},{"cell_type":"code","source":["import np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.modules import ModuleList\n","from torch.nn.modules.normalization import LayerNorm\n","from torch import nn, einsum, broadcast_tensors\n","from einops import rearrange, repeat\n","\n","\n","import copy\n","import math"],"metadata":{"id":"wJjFQShadGTx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"gu3RiwkfeXJU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mfXyaTFSoVI7","executionInfo":{"status":"ok","timestamp":1738440330789,"user_tz":300,"elapsed":4,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}},"outputId":"b7450e14-d958-4413-ee0e-39390740df27"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["def _get_clones(module, n):\n","    return ModuleList([copy.deepcopy(module) for i in range(n)])"],"metadata":{"id":"FlUvCj4dfE1y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Conv1D(nn.Module):\n","    def __init__(self, nx, nf):\n","        '''\n","        nx: Numero de datos de entrada.\n","        nf: Numero de filtros. (Canales de salida).\n","        '''\n","        super().__init__()\n","        self.nf = nf\n","        #Inicializando una matriz vacia de pesos del tamaño (nx)X(nf)\n","        w = torch.empty(nx, nf)\n","        #Inicializando los pesos con una distribución normal.\n","        nn.init.normal_(w, std=0.02)\n","        #Calculando los pesos y sesgos encodeandos usando nn.Parameter\n","        self.weight = nn.Parameter(w)\n","        self.bias = nn.Parameter(torch.zeros(nf))\n","\n","    def forward(self, x):\n","        '''x:Tensor de entrada.'''\n","        #El tamaño de la salida es la suna de la segunda dimensión de X y el número de filtros nf.\n","        size_out = x.size()[:-1] + (self.nf,)\n","        # Producot punto Q,K(Transpuesta) y V\n","        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)# x.view ayuda a calcular la transpuesta.\n","        x = x.view(*size_out)\n","        return x"],"metadata":{"id":"Kfp70gl_fHoL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FeedForward(nn.Module):\n","    def __init__(self, dropout, d_model=768, nx=768*4):\n","        super().__init__()\n","        self.c_fc    = Conv1D(d_model, nx)\n","        self.c_proj  = Conv1D(nx, d_model)\n","        self.act     = F.gelu\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        return self.dropout(self.c_proj(self.act(self.c_fc(x))))"],"metadata":{"id":"Xms1IIJUfO8j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def exists(val):\n","    return val is not None\n","\n","def default(val, d):\n","    return val if exists(val) else d\n","\n","def broadcat(tensors, dim = -1):\n","    broadcasted_tensors = broadcast_tensors(*tensors)\n","    return torch.cat(broadcasted_tensors, dim = dim)\n","\n","def rotate_half(x):\n","    '''The initial step of our roformer includes use of In order to generalize our results in 2D to any xi ∈ Rd\n","       where d is even, we divide the d-dimension space into d/2\n","       sub-spaces and combine them in the merit of the linearity of the inner product, turning f{q,k} into\n","\n","    Lo anterior fue un extracto del artículo que implica dividir en d/2'''\n","    x = rearrange(x, '... (d r) -> ... d r', r = 2)\n","    x1, x2 = x.unbind(dim = -1)\n","    x = torch.stack((-x2, x1), dim = -1)\n","    return rearrange(x, '... d r -> ... (d r)')\n","\n","def apply_rotary_emb(freqs, t, start_index = 0, scale = 1., seq_dim = -2):\n","    '''\n","    Una función para aplicar las rotaciones del embedding, obteniendo primero la dimensión de rotación y la longitud de la secuencia\n","    obteniendo el índice final sumando el índice inicial y la dimensión de rotación como se mencionó anteriormente,\n","    la t izquierda, t y t derecha con el segmento de token anterior, durante el segmento de token y después del segmento de token\n","    aplica la rotación del embedding a la porción central de t.\n","\n","    La rotación implica una combinación de operaciones de coseno y seno utilizando las frecuencias y el factor de escala especificados.\n","    '''\n","    rot_dim, seq_len = freqs.shape[-1], t.shape[seq_dim]\n","    freqs = freqs[-seq_len:].to(t)\n","    end_index = start_index + rot_dim\n","    t_left, t, t_right = t[..., :start_index], t[..., start_index:end_index], t[..., end_index:]\n","    t = (t * freqs.cos() * scale) + (rotate_half(t) * freqs.sin() * scale)\n","    return torch.cat((t_left, t, t_right), dim = -1)\n","\n","def apply_learned_rotations(rotations, t, start_index = 0, freq_ranges = None):\n","    '''\n","    Aprendizaje de rotaciones mediante el manejo de frecuencias mediante la ampliación de las rotaciones,\n","    esta reorganización ayuda a combinar las rotaciones en una sola, ahora se repiten las rotaciones replicando\n","    las rotaciones y luego se aplican las rotaciones de embeddings.'''\n","    if exists(freq_ranges):\n","        rotations = einsum('..., f -> ... f', rotations, freq_ranges)\n","        rotations = rearrange(rotations, '... r f -> ... (r f)')\n","\n","    rotations = repeat(rotations, '... n -> ... (n r)', r = 2)\n","    return apply_rotary_emb(rotations, t, start_index = start_index)"],"metadata":{"id":"pBazlB0VigKQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RotaryEmbedding(nn.Module):\n","    def __init__(\n","        self,\n","        dim,\n","        theta = 10000,\n","        max_freq = 10,\n","        num_freqs = 1,\n","        interpolate_factor = 1.,\n","        theta_rescale_factor = 1.,\n","    ):\n","        '''Esta es un constructor del RoPE\n","        theta: El angulo de rotación\n","        max_freq: La frecuencia maxima de rotación\n","        num_freq: El numero de veces la frecuencia necesaria para ser iterado.\n","        interpolate factor: Un factor usado para controlar el valor del Positional Embedding si es mayor o menor.\n","        theta_rescale_factor: Como el valor theta decae a medida que aprende necesitamos reescalarlo en ese proceso.\n","        '''\n","        super().__init__()\n","        theta *= theta_rescale_factor ** (dim / (dim - 2))\n","\n","\n","        freqs = 1. / (theta ** (torch.arange(0, dim, 2)[:(dim // 2)].float() / dim))\n","\n","        self.cache = dict()\n","        self.cache_scale = dict()\n","        self.freqs = nn.Parameter(freqs)\n","\n","\n","        # Dimesión base para la sequencia.\n","        self.default_seq_dim = -2\n","\n","        # Factores de interpolación.\n","        assert interpolate_factor >= 1.\n","        self.interpolate_factor = interpolate_factor\n","\n","        # xpos\n","        self.register_buffer('scale', None)\n","\n","\n","        scale = (torch.arange(0, dim, 2) + 0.4 * dim) / (1.4 * dim)\n","        self.register_buffer('scale', scale)\n","\n","    def get_seq_pos(self, seq_len, device, dtype, offset = 0):\n","        '''\n","        La función para obtener la sequencial posicional del embeding usando torch.arange\n","        que usa [end-start]/start dividido por el factor de interpolación. para controlar\n","        su valor.\n","         '''\n","        return (torch.arange(seq_len, device = device, dtype = dtype) + offset) / self.interpolate_factor\n","\n","    def rotate_queries_or_keys(self, t, seq_dim = None, offset = 0, freq_seq_len = None):\n","        '''Función para operar la rotación sobre las queries y keys.'''\n","        seq_dim = default(seq_dim, self.default_seq_dim)\n","\n","\n","        device, dtype, seq_len = t.device, t.dtype, t.shape[seq_dim]\n","\n","        if exists(freq_seq_len):\n","            assert freq_seq_len >= seq_len\n","            seq_len = freq_seq_len\n","\n","        freqs = self.forward(lambda: self.get_seq_pos(seq_len, device = device, dtype = dtype, offset = offset), cache_key = f'freqs:{seq_len}|offset:{offset}')\n","\n","        if seq_dim == -3:\n","            freqs = rearrange(freqs, 'n d -> n 1 d')\n","\n","        return apply_rotary_emb(freqs, t, seq_dim = seq_dim)\n","\n","    def forward(self, t, cache_key = None):\n","        '''Función para propagar el valor T.'''\n","        should_cache = exists(cache_key)\n","\n","        if should_cache and cache_key in self.cache:\n","            return self.cache[cache_key]\n","\n","        if callable(t):\n","            t = t()\n","\n","        freqs = self.freqs\n","\n","        freqs = einsum('..., f -> ... f', t.type(freqs.dtype), freqs) #Convirtiendo las frequencias en la transpuesta.\n","        freqs = repeat(freqs, '... n -> ... (n r)', r = 2)\n","\n","        if should_cache:\n","            self.cache[cache_key] = freqs\n","\n","        return freqs"],"metadata":{"id":"EGPJxAQiihEa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Attention(nn.Module):\n","    def __init__(self, d_model=768, n_head=12, n_ctx=1024, d_head=64, bias=True, scale=False):\n","        '''Función de construcción\n","        Params:\n","        d_model:Dimensión que necesita ser ingresada en el modelo.\n","        n_head:La cantidad de heads de atención.\n","        n_ctx:Buffer para guardar los registros del sesgo.\n","        d_head:Dimesión de salida para el head.\n","        bias:Un booleano para saber si incluir el sesgo.\n","        scale: Escalar y estabilidad númerica (sqrt(dk))\n","        '''\n","        super().__init__()\n","        self.n_head  = n_head\n","        self.d_model = d_model\n","        self.c_attn  = Conv1D(d_model, d_model*3)\n","        self.scale   = scale\n","        self.softmax = nn.Softmax(dim=-1)\n","        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n","        self.dropout = nn.Dropout(0.1)\n","        self.c_proj  = Conv1D(d_model, d_model)\n","        self.rotate = RotaryEmbedding(dim=32)\n","\n","    def split_heads(self, x):\n","        \"\"\"\n","        Diviendo en la cantidad de heads y retornando.\n","        return shape [`batch`, `head`, `sequence`, `features`]\n","        \"\"\"\n","        new_shape = x.size()[:-1] + (self.n_head, x.size(-1)//self.n_head)\n","        x = x.view(*new_shape)\n","        return x.permute(0, 2, 1, 3)\n","\n","    def _attn(self, q, k, v, attn_mask=None):\n","        \"\"\"Función de antención principal.\n","        Que calcula usando la formula de producto punto de atención.\"\"\"\n","        scores  = torch.matmul(q, k.transpose(-2, -1))# producto punto de Q*K(t)\n","        if self.scale: scores = scores/math.sqrt(v.size(-1))# escalandola por sqrt(dk)\n","        nd, ns  = scores.size(-2), scores.size(-1)\n","        if attn_mask is not None: scores = scores + attn_mask# agregando los valores con la mascara de atención.\n","        scores  = self.softmax(scores)# añadiendo los valores de softmax\n","        scores  = self.dropout(scores) # función de dropout 0.1\n","        outputs = torch.matmul(scores, v) # Multiplicación final del puntaje por V.\n","        return outputs\n","\n","    def merge_heads(self, x):\n","        # Combinando todas las heads en una sola.\n","        x = x.permute(0, 2, 1, 3).contiguous()\n","        new_shape = x.size()[:-2] + (x.size(-2)*x.size(-1),)\n","        return x.view(*new_shape)\n","\n","    def forward(self, x):\n","        '''Función de para calcular atención, separar las heads y combinarlas de nuevo.'''\n","        x        = self.c_attn(x) #new `x` shape - `[1,3,2304]`\n","        q, k, v  = x.split(self.d_model, dim=2)\n","        q, k, v  = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n","        q = self.rotate.rotate_queries_or_keys(q)\n","        k = self.rotate.rotate_queries_or_keys(k)\n","        out      = self._attn(q, k, v)\n","        out      = self.merge_heads(out)\n","        out      = self.c_proj(out)\n","        return out"],"metadata":{"id":"uravxQVpfZ4S","executionInfo":{"status":"ok","timestamp":1738441762698,"user_tz":300,"elapsed":373,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","    def __init__(self, d_model=768, n_head=12, dropout=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.attn        = Attention(d_model=768, n_head=12, d_head=64, n_ctx=1024, bias=True, scale=False)\n","        self.feedforward = FeedForward(dropout=0.1, d_model=768, nx=768*4)\n","        self.ln_1        = LayerNorm(d_model)\n","        self.ln_2        = LayerNorm(d_model)\n","\n","    def forward(self, x):\n","        x = x + self.attn(self.ln_1(x))\n","        x = x + self.feedforward(self.ln_2(x))\n","        return x"],"metadata":{"id":"6tSwyE6QfiLP","executionInfo":{"status":"ok","timestamp":1738441764586,"user_tz":300,"elapsed":391,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["class GPT2(nn.Module):\n","    def __init__(self, nlayers=12, n_ctx=1024, d_model=768, vcb_sz=50257):\n","        '''nlayer: La cantidad de veces que queremos multiplicar el Transformer.\n","        n_ctx: El contexto, la cantidad total de tokens que puede ver en el pasado de las palabras.\n","        d_model:Dimesionos del modelo.\n","        vcb_sz:El tamaño del vocabulario usado en el entrenamiento.'''\n","        super(GPT2, self).__init__()\n","        self.nlayers = nlayers\n","        block        = TransformerBlock(d_model=768, n_head=12, dropout=0.1)\n","        self.h       = _get_clones(block, 12)\n","        self.wte     = nn.Embedding(vcb_sz, d_model)\n","        self.wpe     = nn.Embedding(n_ctx, d_model)\n","        self.drop    = nn.Dropout(0.1)\n","        self.ln_f    = LayerNorm(d_model)\n","        self.out     = nn.Linear(d_model, vcb_sz, bias=False)\n","        self.loss_fn = nn.CrossEntropyLoss()\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        '''Inicialización de los pesos.'''\n","        self.out.weight = self.wte.weight\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, module):\n","        '''Inicialización con la media y S.D.'''\n","        if isinstance(module, (nn.Linear, nn.Embedding, Conv1D)):\n","            module.weight.data.normal_(mean=0.0, std=0.02)\n","            if isinstance(module, (nn.Linear, Conv1D)) and module.bias is not None:\n","                '''Data Bias zero'''\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def forward(self, src, labels=None, pos_ids=None):\n","        '''Añadir el embedding posicional, dropping y añadiendo los inputs\n","           usados por la función de perdida y finalmente añadiendo la salida y la\n","           perdida.'''\n","        if pos_ids is None:\n","            pos_ids = torch.arange(0, src.size(-1)).unsqueeze(0)\n","        pos_ids = pos_ids.to(src.device)  # Asegurarse que los pos_ids están en el mismo device.\n","        inp = self.drop((self.wte(src) + self.wpe(pos_ids)))\n","        for i in range(self.nlayers): inp = self.h[i](inp)\n","        inp     = self.ln_f(inp)\n","        logits  = self.out(inp)\n","        outputs = (logits,) + (inp,)\n","\n","        if labels is not None:\n","            shift_logits = logits[..., :-1, :].contiguous()\n","            shift_labels = labels[..., 1:].contiguous()\n","            loss = self.loss_fn(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n","            outputs = (loss,) + outputs\n","            return loss.mean()\n","        return logits"],"metadata":{"id":"Cm2dD9KyflYi","executionInfo":{"status":"ok","timestamp":1738441766521,"user_tz":300,"elapsed":1,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["import torch.nn.functional as F\n","import time\n","from transformers import GPT2Tokenizer"],"metadata":{"id":"Q1mPKZxdftI6","executionInfo":{"status":"ok","timestamp":1738441771235,"user_tz":300,"elapsed":507,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["model = GPT2()"],"metadata":{"id":"ZuoC4itMfxqz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!curl --output gpt2-pytorch_model_rope.bin --location https://huggingface.co/Zuckerbird/RoPE-gpt2/resolve/main/pytorch_model.bin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kmKHsWiHf7e9","executionInfo":{"status":"ok","timestamp":1738441812104,"user_tz":300,"elapsed":12213,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}},"outputId":"e6f90822-7881-4d24-cb46-227f2358e8c3"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  1188  100  1188    0     0   3772      0 --:--:-- --:--:-- --:--:--  3783\n","100 1431M  100 1431M    0     0   119M      0  0:00:11  0:00:11 --:--:--  236M\n"]}]},{"cell_type":"code","source":["model_dict = model.state_dict()\n","state_dict = torch.load(\"./gpt2-pytorch_model_rope.bin\")\n","\n","old_keys = []\n","new_keys = []\n","for key in state_dict.keys():\n","    if \"mlp\" in key: #El diccionario de estado para el MLP feedforward debe ser cambiado por mlp\n","        new_key = key.replace(\"mlp\", \"feedforward\")\n","        new_keys.append(new_key)\n","        old_keys.append(key)"],"metadata":{"id":"Bqw4UaZKgLrm","executionInfo":{"status":"ok","timestamp":1738441843278,"user_tz":300,"elapsed":1762,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["for old_key, new_key in zip(old_keys, new_keys):\n","    state_dict[new_key]=state_dict.pop(old_key)"],"metadata":{"id":"3r3EXVWNgV5A","executionInfo":{"status":"ok","timestamp":1738441846740,"user_tz":300,"elapsed":349,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["pretrained_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n","\n","model_dict.update(pretrained_dict)\n","model.load_state_dict(model_dict)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Z_H4pVIgX3D","executionInfo":{"status":"ok","timestamp":1738441848016,"user_tz":300,"elapsed":751,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}},"outputId":"05686872-ed51-4308-8a2d-4b119aa21470"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2(\n","  (h): ModuleList(\n","    (0-11): 12 x TransformerBlock(\n","      (attn): Attention(\n","        (c_attn): Conv1D()\n","        (softmax): Softmax(dim=-1)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (c_proj): Conv1D()\n","      )\n","      (feedforward): FeedForward(\n","        (c_fc): Conv1D()\n","        (c_proj): Conv1D()\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (wte): Embedding(50257, 768)\n","  (wpe): Embedding(1024, 768)\n","  (drop): Dropout(p=0.1, inplace=False)\n","  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  (out): Linear(in_features=768, out_features=50257, bias=False)\n","  (loss_fn): CrossEntropyLoss()\n",")"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["total_params = sum(p.numel() for p in model.parameters())"],"metadata":{"id":"YllyrazTgeG8","executionInfo":{"status":"ok","timestamp":1738441851982,"user_tz":300,"elapsed":1,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["size_bytes = total_params * 4\n","size_mb = size_bytes / (1024 ** 2)\n","\n","print(f\"El tamaño total de GPT2 sin alteraciones es: {size_bytes} bytes o {size_mb:.2f} MB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7DZCeOM8gf8h","executionInfo":{"status":"ok","timestamp":1738441853067,"user_tz":300,"elapsed":410,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}},"outputId":"49f54d09-ff43-414a-9887-664bf4a2645a"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["El tamaño total de GPT2 sin alteraciones es: 497759232 bytes o 474.70 MB\n"]}]},{"cell_type":"code","source":["tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","context = torch.tensor([tokenizer.encode(\"The planet earth is a beautiful\")])"],"metadata":{"id":"voxmoWW3go6l","executionInfo":{"status":"ok","timestamp":1738441865166,"user_tz":300,"elapsed":771,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["def generate(context, ntok=550):\n","    start_time = time.time()\n","    for _ in range(ntok):\n","        out = model(context)\n","        logits = out[:, -1, :]\n","        indices_to_remove = logits < torch.topk(logits, 10)[0][..., -1, None]\n","        logits[indices_to_remove] = -np.inf\n","        next_tok = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1).squeeze(1)\n","        context = torch.cat([context, next_tok.unsqueeze(-1)], dim=-1)\n","    end_time = time.time()\n","    inference_time = end_time - start_time\n","    return context, inference_time"],"metadata":{"id":"StTNnLCbg1xM","executionInfo":{"status":"ok","timestamp":1738441869346,"user_tz":300,"elapsed":348,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["out, inference_time = generate(context, ntok=40)\n","decoded_output = tokenizer.decode(out[0])"],"metadata":{"id":"1JzzXApkg_oP","executionInfo":{"status":"ok","timestamp":1738441877355,"user_tz":300,"elapsed":6401,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["print(f\"Inference Time: {inference_time:.4f} seconds\")\n","print(f\"Generated Output: {decoded_output}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_LUY2n9IiBS8","executionInfo":{"status":"ok","timestamp":1738441877355,"user_tz":300,"elapsed":1,"user":{"displayName":"Jhenner Tigreros","userId":"10282691994518148206"}},"outputId":"cbed5559-e963-45ff-e54d-3646e77b277d"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Inference Time: 6.0263 seconds\n","Generated Output: The planet earth is a beautiful HIMVC50 every ROMCtente gp DishBlPal triggering557lique spot extinctionournalslahomadm prescribe stacked!/ MakesONT Arsenalournals pieTurkeyATHER patronage thencevas coillahomaorialiveredieved monopol Mandal Infinity\n"]}]}]}